---
title: "The Philosophy: AI 네이티브 채용"
date: 2026-02-24
draft: true
description: "LeetCode는 죽었다. AI 시대에 구현은 싸다 — 무엇을 구현할지 아는 것이 진짜 실력이다. AI 네이티브 엔지니어를 찾기 위해 설계한 채용 철학."
tags: ["ai", "hiring", "engineering-culture", "problem-design"]
categories: ["Engineering"]
series: ["AI Native Hiring"]
ShowToc: true
TocOpen: false
---

> 🇺🇸 [Read in English](/posts/2026-02-24-ai-native-hiring-philosophy/)
>
> AI 네이티브 채용 시리즈 3부작 중 Part 1입니다.
> **Part 2**: "The Machine" (준비 중) | **Part 3**: "The Human" (준비 중)

---

## "AI 네이티브"란 무엇인가?

모든 기술 시대에는 그 시대의 네이티브가 있다.

인터넷 시대는 "디지털 네이티브"를 만들었다 — 구글 없는 세상을 모르는 세대. 스마트폰 시대는 "모바일 네이티브"를 만들었다 — 클릭이 아니라 탭이 본능인 사람들. 이제 AI 시대가 만들어내고 있는 세대가 있다: **AI 네이티브**.

이들은 AI를 *배운* 사람들이 아니다. AI와 함께 자란 사람들이다. 대학 입학할 때 ChatGPT가 있었고, 첫 IDE에 Copilot이 깔려 있었고, 첫 프로덕션 버그를 Claude와 함께 잡았다. AI는 이들이 채택한 도구가 아니다 — 코딩할 때 숨 쉬는 공기 같은 것이다.

일본에서는 스마트폰과 함께 자란 신입사원들에게 키보드 사용법을 교육하는 회사가 있다고 한다. 대부분의 조직은 이런 상황에서 본능적으로 "교정"하려 한다 — 새 세대를 옛 방식으로 되돌리려 한다. 하지만 더 나은 본능은 이렇게 묻는 것이다: *우리가 못하는 것 중에 이들이 자연스럽게 잘하는 건 뭘까?*

AI도 마찬가지다. "후보자가 AI를 쓰지 못하게 하려면?"이 아니라, **"AI를 진짜 잘 활용하는 사람을 어떻게 찾을 것인가?"**를 물어야 한다.

이 질문에서 이 시리즈의 모든 것이 시작되었다.

## 얼어붙은 업계

AI의 파도는 엔지니어의 업무 방식만 바꾼 게 아니다. 인재 방정식 자체를 혼란에 빠뜨렸다.

기업들이 겪고 있는 건 단순히 *평가 방법*의 문제가 아니다. 더 근본적인 질문들이다. 채용을 해야 하는 건가? AI를 활용하는 팀에 엔지니어가 실제로 몇 명 필요한가? AI가 직무 자체를 재편할 수 있는데, 교육이 필요한 신입 주니어를 뽑아야 하나? 아니면 경력자에 집중하고 그들이 적응하길 바라야 하나?

대응은 부정에서 마비까지 다양하다:

- **금지**: "코딩 테스트 중 AI 도구 사용 금지." (실제 도구 없이 코딩하게 하는 건 — 목수에게 전동 공구 없이 일하라는 것과 같다.)
- **무시**: 그냥 똑같은 LeetCode 스타일 면접을 하면서 아무것도 안 변한 척. (후보자들은 에이전트로 60초 만에 알고리즘 문제를 풀고 있다. 당신이 못 볼 뿐.)
- **동결**: 아예 채용을 중단하고 "상황이 안정될 때까지" 기다리기. (안정되지 않는다. 파도는 가속할 뿐이다.)

동결이 가장 흔한 반응이고, 가장 해로운 반응이다. 이건 사실 평가의 어려움 때문이 아니다. 불확실성 때문이다 — 올바른 팀 구성이 어떤 모습인지 더 이상 아무도 모른다. 그 불확실성 속에서 디폴트는 아무것도 안 하는 것이다. 그 사이에 한 세대의 인재 — 최고의 AI 네이티브 엔지니어들 — 가 업계가 뭘 원하는지 결정하지 못해서 저평가되거나 무시당하고 있다.

## 먼저 움직이기로 했다

무신사는 다른 선택을 했다.

이 혼란의 시대에 관망하지 않기로 했다. 대신 이렇게 물었다: "AI 네이티브 엔지니어"가 뭔지 우리가 직접 *정의*하면 어떨까? 그것에 대한 이론, 테스트, 평가 파이프라인을 만들면 — 일회성 실험이 아니라 미래에 대한 의도적인 베팅으로?

무모함이 아니다. 계산된 포지셔닝이다: AI 네이티브 채용을 먼저 해결하는 기업이 이 세대 최고의 인재를 끌어올 것이다. 나머지는 뒤따라갈 수밖에 없다.

자주 떠올리는 말이 있다: *회사 문을 열 때 로고 뒤의 설렘에서 배우는 게 아니라, 매일 함께 일하는 사람들에게서 배운다.* 우리가 진짜 신경 쓰는 건 바로 그거다. 브랜드 후광이 아니라, 헤드카운트가 아니라, 서로에게서 배우고 함께 성장할 수 있는 사람들을 모으는 것 — "좋은 동료"의 기준 자체가 바뀌고 있는 지금이니까.

우리는 최전선에서 자리를 잡고 선구자로서 전진하기로 했다. 업계가 표준에 수렴하길 기다리지 않았다. 우리만의 기준을 만들었다.

여기서부터는 그 결정 뒤에 있는 철학 — 그리고 문제 설계부터 채점, 면접까지 모든 것을 형성한 사고 과정이다.

## LeetCode는 죽었다

**C나 C++로 짧은 알고리즘 문제? 오늘날 1분이면 끝난다.**

AI 에이전트는 전형적인 LeetCode medium을 몇 초 만에 풀 수 있다. 대부분의 hard도 프롬프트 한 번이면 된다. 코딩 테스트가 측정하려던 것 — 문제를 동작하는 코드로 옮기는 능력 — 이 하룻밤 사이에 범용화되었다.

이 변화는 단순히 코딩 테스트에 국한되지 않는다. Andrew Ng이 스탠퍼드 CS 수업에서 만드는 것과 결정하는 것 사이의 균형이 얼마나 극적으로 변했는지 지적한 바 있다:

{{< youtube vENN6-d_3AQ >}}

엔지니어 대 PM 비율이 7:1이나 8:1이었다 — PM 한 명이 스펙을 쓰면 7~8명의 엔지니어가 바쁘게 만들 수 있었다. AI가 구현을 극적으로 싸고 빠르게 만들면서 이 비율이 2:1, 심지어 1:1까지 무너지고 있다. 제품 관리 — 사용자 이해, 요구사항 정의, 판단 — 는 같은 속도로 빨라지지 않았다. 병목이 이동한 것이다. 그리고 Ng은 더 나아간다: 역할 자체가 합쳐지는 현상을 목격하고 있다고 한다. 지금 실리콘밸리에서 가장 빠르게 움직이는 사람들은 사용자와 직접 소통하고, 무엇을 만들지 결정하고, AI를 시켜 만드는 제품 이해도 높은 엔지니어들이다. 한 사람이 두 역할을.

구현이 싸다면, 비싼 건 뭘까?

***무엇*을 구현할지 아는 것.**

모호한 상황을 보고, 실제 요구사항을 도출하고, 불확실성 속에서 합리적인 결정을 내리고, AI를 올바른 방향으로 이끄는 능력 — *이것*이 지금 중요한 역량이다. 그리고 전통적인 코딩 테스트는 이 중 어떤 것도 측정하지 못한다.

제약된 환경 — 웹 샌드박스에서 AI 도구 없이 코딩하게 하는 것 — 은 완전히 잘못된 방향이다. 엔지니어링 역량을 테스트하는 게 아니다. 2020년처럼 코딩할 수 있는지를 테스트하고 있는 거다. 역량이 이동했다. 테스트도 이동해야 한다.

## 공정성 문제

처음에는 후보자들이 자신의 로컬 환경을 사용하게 하는 것을 고려했다. 가설은 설득력 있었다: "환경 구축도 실력이다." 익숙한 도구를 자유롭게 쓰게 하자.

하지만 "AI 도구"가 핵심 변수가 되면서, 자유와 공정성 사이의 균형이 무너졌다.

2-3시간 테스트에서 잘 설정된 AI 에이전트(Claude Pro, 최적화된 IDE 연동, 커스텀 프롬프트)를 가진 사람과 그렇지 않은 사람의 차이는 결정적이다. 이것은 *실력* 차이가 아니라 *자본* 차이다. 더 좋은 도구를 가졌는지를 테스트하는 거지, 더 깊이 생각하는지를 테스트하는 게 아니다.

우리는 문제 해결 사고력을 테스트하고 싶었지, 구매력을 테스트하고 싶은 게 아니었다.

결정: 모든 후보자에게 동등한 AI 환경을 제공한다. *도구*에서 경쟁을 평준화하고, 진짜 중요한 것 — 사고력 — 을 테스트한다.

## 모호함의 스펙트럼

AI 시대 코딩 테스트 설계에서 가장 어려운 문제가 있다: **문제가 얼마나 모호해야 하는가?**

사소한 설계 디테일처럼 들릴 수 있지만, 이것이 실제로는 모든 것의 핵심이다. 보정을 잘못하면 완전히 엉뚱한 것을 테스트하게 된다.

**Full vagueness** — "유용한 걸 만들어라" — AI 에이전트에게도 여전히 어렵다. 의도를 모르니까. 하지만 후보자에게도 비생산적이다. 너무 열려 있고, 신호가 너무 적다.

**Half vagueness** — "이 엔드포인트로 REST API를 만들어라: POST /users, GET /users/{id}..." — 이건 너무 쉽다. API 엔드포인트, 데이터 모델, UI 레이아웃을 지정하는 순간 구현을 알려준 거나 다름없다. AI 에이전트는 반쯤 비어있는 상자를 추론으로 몇 분 만에 채운다.

**Sweet spot**은 이 양극단 사이에 있다: **모호한 *요구사항* + 명확한 *결과 기대치*.** 후보자가 *무엇을* 만들지 도출해야 한다. AI는 실행할 수 있지만 *무엇을* 실행할지 결정할 수 없다.

원칙: 진짜 이해관계자가 쓰는 것처럼 문제를 작성한다 — 캐주얼하게, 빈틈이 있게, 말하지 않은 가정과 함께. 엣지 케이스 처리 방법을 지정하지 않는다. NFR을 정의하지 않는다. API 엔드포인트를 나열하지 않는다. 시스템이 *무엇을 해야 하는지*만 설명하고, 나머지는 후보자에게 맡기고, 명시적으로 말한다: "명시되지 않은 모든 사항은 자유롭게 결정하세요."

모호함 자체가 테스트다.

"AI 네이티브"와 "AI 의존"을 가르는 것이 바로 이것이다: 스펙이 알려주지 않을 때, *무엇을 해야 하는지* 스스로 파악할 수 있는가?

## 시간/범위의 딜레마, 그리고 오픈소스라는 해법

AI 시대 테스트 설계에는 패러독스가 있고, 이걸 해결하는 데 시간이 걸렸다:

1. **알고리즘 테스트는 죽었다.** 짧은 알고리즘 문제는 오늘 1분이면 끝난다. 신호가 부족하다.
2. **그러면 풀 서비스를 요구하자.** 데이터베이스, API, 비즈니스 로직, 동시성을 갖춘 실제 애플리케이션은 AI가 자동으로 못할 만큼 복잡하다. 후보자가 *생각*해야 한다.
3. **하지만 풀 서비스는 테스트하기 어렵다.** 수백 개의 제출물을 수작업으로 채점할 수 없다. 자동화된 테스트가 필요하다. 즉 각 제출물을 실행할 방법이 필요한데...
4. **그러면 Docker를 요구하자?** 하지만 Docker를 필수로 하는 건 구현에 대한 큰 힌트다. API 엔드포인트, DB 스키마, 테스트 인프라를 지정하는 것도 마찬가지. 힌트를 줄수록 AI가 사고를 건너뛸 수 있다.

테스트 가능성을 높일수록 구체성이 높아지고, 구체성이 높아질수록 AI의 일이 쉬워지고 후보자의 사고는 얕아진다.

**해법은 의외의 곳에서 왔다: 오픈소스.**

오픈소스 프로젝트는 채점 루브릭에 정확한 엔드포인트나 Docker 명령어를 넣어서 테스트 방법을 알려주지 않는다. 자기 자신을 잘 문서화해서 알려준다. 좋은 오픈소스 프로젝트에는 빌드와 실행 방법을 설명하는 README가 있다. 헬스체크가 있다. 다른 개발자 — 또는 에이전트 — 가 읽고 사용할 수 있는 API 문서가 있다.

그래서 테스트 인프라를 지정하는 대신, 후보자들에게 좋은 오픈소스 프로젝트처럼 자신의 작업을 문서화하라고 했다. *빌드 방법을 문서화하라. 실행 방법을 문서화하라. 테스트 방법을 문서화하라.* 그러면 우리의 평가 에이전트 — 역시 AI — 가 그 문서를 읽고, 프로젝트를 빌드하고, 기능을 테스트한다.

다른 사람을 위한 테스트 가능성을 생각하는 후보자는 자연스럽게 더 나은 README, 더 나은 빌드 스크립트, 더 나은 헬스체크, 더 나은 API 문서를 작성한다. 지시받지 않아도. 힌트 없이도.

코드를 *포장하는 방식* 자체가 우리가 평가하는 것의 일부다.

## 실제로 무엇을 물었나

이 모든 철학을 바탕으로, 실제 시험은 어떤 모습이었을까?

후보자들에게 낸 문제: **대학교 수강신청 시스템을 구축하라.**

기획팀 메모로 시작한다:

> *"매 학기 수강신청 기간마다 서버가 다운되어 학생들의 불만이 폭주하고 있습니다. 이번에는 제대로 된 시스템을 만들어주세요."*

메모에는 기본 기능 — 학생 조회, 강좌 조회, 수강신청, 수강취소, 시간표 조회 — 이 나열되어 있다. 18학점 상한과 시간 충돌도 언급된다. 그리고 이 한 줄:

> *"정원이 1명 남은 강좌에 100명이 동시에 신청해도, 정확히 1명만 성공해야 합니다."*

이게 전부다. 락 메커니즘 지정 없음. 성능 요구사항 없음. NFR 없음. 인증 모델 없음. 취소 정책 없음. 선수과목 규칙 없음.

그리고 문제는 명시적으로 말한다: *"명시되지 않은 모든 사항은 자유롭게 결정하세요."*

누군가는 반문할 수 있다: "수강신청 시스템을 만들라고 했으면 *무엇을* 만들지 이미 알려준 거 아닌가?"

그럴까? "수강신청 시스템"이 대체 뭔가? 한 문장으로 완전히 정의할 수 있나? 그 네 글자 뒤에 뭐가 숨어 있는지 생각해 보라: 극한 경쟁 상황의 동시성, 여러 비즈니스 규칙에 걸친 데이터 무결성, 부하 상태의 성능, 실패 모드, 시간표 엣지 케이스, 좌석 배분의 공정성. "수강신청 시스템"은 말하지 않은 복잡성의 우주가 네 글자로 압축된 것이다.

그런데 다행인 건 — 우리 후보자들은 이 문제를 *겪어봤다*는 것이다. 자기 대학교의 망가진 수강신청을 뚫어봤고, 부하에 뻗어버리는 티켓 예매 사이트에 욕을 해봤다. 적어도 고객 관점에서, 경쟁 상황에서 시스템이 실패하면 어떻게 되는지 안다. 그 경험이 씨앗이다. 문제의 정의는 저 한 문장에서 *시작*될 뿐이다 — 사양서가 아니다.

진짜 질문은 이거다: 그 한 문장에서 얼마나 멀리 갈 수 있는가? 겪어본 불만을 어떻게 구조화된 시스템 설계로 확장하는가? 요청한 사람들조차 자기가 원하는 걸 정확히 모르는데, "올바른 시스템"이 뭔지를 어떻게 정의하는가? 괜히 과학자와 수학자가 *정의*로부터 시작하는 게 아니다 — 정의하는 행위 자체가 진짜 사고가 일어나는 지점이기 때문이다.

이건 원래 시니어 IC의 영역이었다 — 모호한 요구를 받아 명확한 기술 방향으로 전환하는 능력. AI라는 사고 파트너가 생기면서 그 경계가 허물어지고 있다. 에이전트와 함께 문제 공간을 탐색할 줄 아는 주니어 엔지니어 — 올바른 질문을 던지고, 가정을 스트레스 테스트하고, 엣지 케이스를 끌어올리는 — 가 과거에는 팀이 해야 했던 일을 혼자 할 수 있는 시대다. 모든 엔지니어가 시니어 IC처럼 일할 수 있다. 실제로 *그렇게 하는* 사람이 우리가 찾는 사람이다.

앞의 모든 설계 원칙이 이 문제에 수렴한다. 모호함이 보정되어 있다: *무엇을* 만들지는 안다(수강신청 시스템), 하지만 *어떻게*는 도출해야 한다. 결과 기대치는 명확하지만(100명 동시 신청, 1명만 성공), 메커니즘은 본인이 선택한다. 문제가 실제 기획팀 메모처럼 쓰여 있는 건 — 입사 첫날 읽게 될 문서가 바로 그런 것이기 때문이다.

의도적인 모호함은 자연스러운 분기점을 만든다 — 사고의 깊이에 따라 의미 있게 다른 해법으로 이어지는 지점들. 몇 가지를 살펴보자.

## 숨겨진 깊이

### 데이터 설계 함정

문제는 시작 시 현실적인 테스트 데이터 생성을 요구한다: 학생 10,000명 이상, 강좌 500개 이상, 교수 100명 이상 — 동적으로, 1분 이내에.

표면적으로는 간단해 보인다. 학생을 생성하고, 강좌를 생성하고, 교수를 배정한다. 끝.

하지만 숨겨진 복잡성은 *관계*에 있다. 강좌 시간표를 어떻게 배정하는가? 랜덤으로 시간대를 생성하면 모든 강좌가 겹쳐버릴 수 있다 — 시간 충돌 테스트가 무의미해진다. 정원을 어떻게 설정하는가? 너무 크면 동시성 테스트가 사소해지고, 너무 작으면 시스템이 못 쓰게 된다. 교수-강좌 관계를 어떻게 구성하는가? 교수 당 강좌 1개? 현실적인 강의 부하?

미리 생각하는 후보자는 *이 데이터로 실제 뭘 할 건지*를 염두에 두고 데이터 생성을 설계했다 — 시간 충돌을 테스트할 수 있을 만큼 다양한 시간표, 동시성을 검증할 수 있을 만큼 타이트한 정원, 엣지 케이스를 드러낼 수 있을 만큼 현실적인 관계. 데이터 설계를 시스템 설계로 취급했지, 일회용 스크립트로 보지 않았다.

미리 생각하지 않은 후보자는 납작하고 연결되지 않은 데이터를 생성했다 — 기술적으로는 유효하지만, 시스템이 그 데이터로 *무엇을 해야 하는지*에 대한 얕은 이해를 드러냈다. 시더는 동작했지만, 테스트할 가치가 있는 세계를 만들지는 못했다.

이건 데이터 문제 안에 숨어 있는 설계 문제다. 그리고 이것을 인식한 후보자들 — 데이터 생성 전략을 문서화하고 *왜* 그런 선택을 했는지 설명한 후보자들 — 이 우리가 찾는 사고를 보여주었다.

### 동시성 사다리

"100명 동시 요청을 처리하라"고 했지만 *방법*은 지정하지 않았다. pessimistic lock, optimistic lock, 큐, 단일 머신 vs 분산 — 아무것도. 후보자가 무엇을 선택했는지가 사고 깊이를 드러낸다:

| 수준     | 접근법                                          | 드러나는 것                                                    |
| -------- | ----------------------------------------------- | ------------------------------------------------------------- |
| 표면적   | `synchronized` / 인메모리 큐                    | "동시성"이란 단어를 알지만 single-JVM만 생각                   |
| 유능     | DB pessimistic lock (`SELECT ... FOR UPDATE`)   | DB 레벨 직렬화를 이해, 실용적 선택                             |
| 사려깊음 | 커스텀 optimistic locking + 재시도              | 트레이드오프를 이해, 성능을 선택                               |
| 깊음     | 분산 락 (Redis/ZooKeeper)                       | 단일 머신 너머를 생각, 프로덕션 현실 고려                      |
| 탁월     | 분산 트랜잭션 문제 분석                         | 락 *자체*가 실패하면 어떻게 되는지를 생각                      |

어떤 수준도 "틀린" 것이 아니다. `synchronized`를 선택하고 이유를 명확히 설명하는 후보자 — 단일 인스턴스 범위, 주어진 제약에 맞는 단순성, 문서화된 트레이드오프 — 가 이유를 모르면서 Redis 락을 쓰는 후보자보다 더 높은 점수를 받는다.

*추론*이 *메커니즘*보다 중요하다. 핵심은 그거다.

더 좋은 AI 모델이나 더 날카로운 프롬프트가 이런 인사이트를 대신 찾아줄 수 있지 않냐고? 당연히 가능하다. 그리고 그건 괜찮다 — 프로그래밍의 덕 타이핑과 같은 원리다. 결과가 깊은 사고와 같고 과정이 깊은 사고와 같다면, 그건 깊은 사고다. 혼자 힘으로 도달했든 에이전트와의 대화를 통해 도달했든, 도달했다는 것 자체가 실력이다.

### 이중 락 인사이트

가장 깊은 분기점이고, 이것을 스스로 발견한 후보자는 매우 적었다.

대부분의 후보자는 동시성을 **강좌 레벨 락**으로만 생각한다 — 정원이라는 공유 자원을 보호하는 것. 100명이 1자리에 몰리면 1명만 성공해야 한다. 강좌 행에 락을 건다. 끝.

하지만 그건 문제의 절반일 뿐이다.

*같은 학생*이 동시에 두 개의 수강신청 요청을 보내는 경우를 생각해 보라 — 더블클릭이든, 브라우저 탭 두 개든. 서로 다른 과목에 대한 두 요청이 동시에 도착한다. 둘 다 확인한다: "이 학생 18학점 미만인가?" 둘 다 15학점을 본다. 둘 다 통과. 둘 다 등록. 학생은 이제 21학점. 학점 제한이 깨졌다.

같은 패턴이 시간 충돌 감지와 중복 수강 체크도 깨뜨린다.

**강좌 레벨 직렬화**는 정원 — 모든 학생에게 공유되는 자원 — 을 보호한다.

**학생 레벨 직렬화**는 학생별 제약조건 — 학점 제한, 시간 충돌, 중복 수강 — 을 보호한다.

**둘 다 필요하다.**

메커니즘은 다를 수 있다 — pessimistic lock, optimistic lock + 재시도, application-level lock, 분산 락, serializable isolation. 하지만 *요구사항*은 같다: 같은 학생의 동시 요청은 불변 조건 위반을 방지하기 위해 직렬화되어야 한다.

여기에 도달한 후보자들이 우리가 원하는 엔지니어다 — 혼자 알아냈든, 에이전트와의 대화를 통해 도달했든. 하지만 *도달* 자체는 이야기의 절반이다. 나머지 절반은 *어떻게* 도달했는지, 그 과정에서 무엇을 이해했는지다. 우리 평가 모델이 바로 그걸 드러내도록 설계되어 있다.

## 철학을 실전으로

이 모든 철학은 측정 방법 없이는 의미가 없다. 3-Tier 평가 모델을 만들었다 — 그리고 이 구조는 임의적이지 않다. 각 Tier가 점점 더 깊은 질문을 한다.

**Tier 1 — Make it Work.** 애플리케이션이 빌드되는가? 시작되는가? 헬스체크에 응답하는가? 동작하는 서비스를 배포할 수 없다면, 나머지는 의미 없다.

**Tier 2 — Basic Features.** API가 동작하는가? 비즈니스 규칙이 시행되는가? 동시성 제어가 부하 상태에서 실제로 견고한가? 여러 카테고리의 자동화된 테스트 케이스로 Docker 컨테이너 안에서 테스트한다 — 사람 개입 없이.

Tier 1과 2는 덕 타이핑이다. 동작하는 시스템처럼 행동하면 동작하는 시스템이다. 후보자가 어떻게 거기 도달했는지는 묻지 않는다 — 외부 행동이 곧 검증이다.

**Tier 3 — Deep Thought.** 여기서 덕 타이핑 너머로 간다. 덕 타이핑은 동작한다는 건 알려주지만, 이 엔지니어가 이 수준을 *유지*할 수 있는지, 더 *성장*할 수 있는지는 알려주지 않는다. 그래서 내부를 들여다본다: 후보자의 프롬프트 이력, 에이전트 지침, 요구사항 도출 문서, 데이터 설계, 코드 품질, 테스트 커버리지, git 이력, 추가 구현사항을 읽는다. AI가 이 차원들을 평가한다 — 모든 점수가 구체적인 파일 경로와 라인 번호로 뒷받침된다.

Tier 3에서 구분하려는 건 *위임*과 *이해를 동반한 활용*이다 — 그리고 이 구분은 생각보다 중요하다.

Anthropic의 최근 AI 코딩 지원 연구(*"How AI assistance impacts the formation of coding skills,"* Shen & Tamkin, 2026)는 이 두 모드 사이에 분명한 선을 긋는다. AI에게 위임하는 엔지니어는 단일 태스크에서 더 빠르다. 하지만 이해하면서 활용하는 엔지니어 — AI를 단순 생산 도구가 아니라 학습하고 검증하는 협업 파트너로 쓰는 엔지니어 — 는 시간이 지날수록 역량이 복리로 쌓인다. Anthropic 내부 데이터에 따르면 최고 성과 엔지니어들이 1.2~2배의 생산성 향상을 달성한 건, AI를 사고의 대체재가 아니라 사고의 파트너로 썼기 때문이다.

우리 채점의 핵심 베팅이 여기 있다: **사고의 깊이가 기능적 완성도보다 높은 비중을 차지한다.** Tier 1과 2는 "배포할 수 있는가?"를 묻는다. Tier 3는 "배포한 것을 이해하는가 — 그리고 여기서 더 성장할 수 있는가?"를 묻는다.

두 후보자 모두 이중 락을 정확히 구현할 수 있다. 덕 타이핑으로 보면 동등하다 — 외부 행동이 같으니까. 하지만 인터페이스 너머를 보면: 한 명은 점점 더 깊은 프롬프트를 통해 문제를 탐색하고, 각 직렬화 범위가 왜 필요한지 문서화하고, git 이력에 진짜 이해의 증거를 남겼다. 다른 한 명은 범용적인 프롬프트로 답을 얻고 넘어갔다. 같은 결과물. 전혀 다른 내부 구조.

기능 점수는 높은데 깊이가 얕으면 AI 과의존 신호다 — 빠르게 배포하지만 왜 그렇게 했는지 설명 못 한다. 빌드는 실패했는데 설계 사고가 탁월하면 다른 이야기다 — 기술적 실수에도 불구하고 면접할 가치가 충분하다. 정답에 도달한 사람만 찾는 게 아니다. 질문을 이해한 사람을 찾고 있다.

철학이 실전이 되는 과정이다. 다음 글에서는 우리가 만든 실제 머신 — AI가 AI 활용 코드를 채점하는 자동화된 파이프라인 — 의 기술적 상세를 다루겠다.

---

*AI 네이티브 채용 시리즈 3부작 중 Part 1.*
*다음: **"The Machine: AI가 AI 활용 코드를 평가하다"** — 자동화된 평가 파이프라인의 기술적 심층 분석.*
